#!/usr/bin/env bash

# on exit call_unsetup
trap "call_unsetup \"0\"" INT EXIT


# Setup a debugger to run comdb2 server
setup_debugger() {
    DEBUG_PREFIX=

    if [[ -n ${DEBUGGER} ]]; then
        case ${DEBUGGER} in
        gdb)
            DEBUG_PREFIX="gdb --args"
            ;;
        valgrind)
            DEBUG_PREFIX="valgrind --track-origins=yes --log-file=$TESTDIR/$TESTCASE.valgrind"
            ;;
        memcheck)
            DEBUG_PREFIX="valgrind --leak-check=full --show-reachable=yes --track-origins=yes --leak-resolution=high --num-callers=30 --log-file=$TESTDIR/$TESTCASE.valgrind"
            ;;
        callgrind)
            DEBUG_PREFIX="valgrind --tool=callgrind --instr-atstart=no --dump-instr=yes --collect-systime=yes --collect-jumps=yes --callgrind-out-file=$TESTDIR/$TESTCASE.callgrind"
            if [[ -n ${COLLECTFUNC} ]]; then
                # collect info on $COLLECTFUNC only
                DEBUG_PREFIX="valgrind --tool=callgrind --collect-atstart=no --toggle-collect="${COLLECTFUNC}" --dump-instr=yes --collect-jumps=yes --callgrind-out-file=$TESTDIR/$TESTCASE.callgrind"
            fi
            ;;
        drd)
            DEBUG_PREFIX="valgrind --tool=drd --read-var-info=yes "
            ;;
        helgrind)
            DEBUG_PREFIX="valgrind --tool=helgrind --log-file=$TESTDIR/$TESTCASE.helgrind"
            ;;
        cachegrind)
            DEBUG_PREFIX="valgrind --tool=cachegrind --cachegrind-out-file=$TESTDIR/$TESTCASE.cachegrind"
            ;;
        massif)
            DEBUG_PREFIX="valgrind --tool=massif --massif-out-file=$TESTDIR/$TESTCASE.massifgrind"
            ;;
        perf)
            DEBUG_PREFIX="perf record -o $TESTDIR/$TESTCASE.perfdata -g -s "
            # get report of performance via perf report -i $TESTDIR/$TESTCASE.perfdata
            # or perf annotate -i $TESTDIR/$TESTCASE.perfdata
            ;;
        sched-perf)
            # this one needs root access: please run sudo and type password so it gets cached beforehand
            # once this completes, you can look at the output this way:
            # chown $USER test_XXX/YYYY.perfdata
            # perf report -T -n -i test_XXX/YYYY.perfdata
            DEBUG_PREFIX="sudo perf record -s -e sched:sched_stat_sleep -e sched:sched_switch -e sched:sched_process_exit --call-graph dwarf -o $TESTDIR/$TESTCASE.perfdata -g "
            ;;
        strace)   # strace syscalls: -tt -T for timing information, -f for threads, -C summary
            DEBUG_PREFIX="strace -tt -T -f -C -o $TESTDIR/$TESTCASE.strace"
            ;;
        mutrace)   # mutex contention detection tool
            DEBUG_PREFIX="mutrace "
            ;;
        *)
            DEBUG_PREFIX=${DEBUGGER}
            ;;
        esac
    fi

    export DEBUG_PREFIX
}

setup_debugger

TEST_TIMEOUT=${TEST_TIMEOUT:-5m}
if [[ "$(uname -m)" == "armv7l" ]] ; then
    t=${TEST_TIMEOUT%%m}
    TEST_TIMEOUT=$(($t * 3 + 2))m
elif [[ "$(uname -m)" == "aarch64" ]] ; then
    t=${TEST_TIMEOUT%%m}
    TEST_TIMEOUT=$(($t * 2 + 2))m
elif [[ "${DEBUG_PREFIX}" == "valgrind"* ]]; then
    t=${TEST_TIMEOUT%%m}
    TEST_TIMEOUT=$(($t * 10 + 2))m
fi

SETUP_TIMEOUT=${SETUP_TIMEOUT:-4m}

if [[ -n "$NUMNODESTOUSE" ]] ; then
    ncl=`echo $CLUSTER | tr ' *' '\n' | sed '/^[[:space:]]*$/d' | shuf -n $NUMNODESTOUSE | xargs echo`
    # from now on, CLUSTER will be a subset of original machines
    export CLUSTER=$ncl
fi


export HOSTNAME=${HOSTNAME:-`hostname`}
export CLEANUPDBDIR=${CLEANUPDBDIR:-1}
export VERIFY_DB_AT_FINISH=${VERIFY_DB_AT_FINISH:-$((2-CLEANUPDBDIR))} # if not specified, depend on $CLEANUPDBDIR
source $TESTSROOTDIR/setup.common
export PATH="${paths}/:${PATH}"
export pmux_port=${PMUXPORT:-5105}  # assign to 5105 if it was not set as a make parameter
TEST_LOG=${TESTDIR}/test.log
successful=0

DATETIME=$(date +"%Y-%m-%d %H:%M:%S")
echo Starting $TESTCASE with id $TESTID at $DATETIME >> ${TEST_LOG}
mkdir -p ${TESTDIR}/logs/

call_unsetup() {
    if [[ $COMDB2_UNITTEST == 1 ]] || [[ "$LEAVEDBRUNNING" == "1" ]] ; then 
        return
    fi

    ${TESTSROOTDIR}/unsetup $successful &> >(gawk '{ print strftime("%H:%M:%S>"), $0; fflush(); }' | tee ${TESTDIR}/logs/${DBNAME}.unsetup | cut -c11- | grep "^!" )
}

warn_long_setup() {
    start=$(date +%s)
    ( ${TESTSROOTDIR}/setup &> >(gawk '{ print strftime("%H:%M:%S>"), $0; fflush(); }' | tee ${TESTDIR}/logs/${DBNAME}.setup | cut -c11- | grep "^!" ) ) &
    pid=$!
    kill -0 $pid >/dev/null 2>&1
    r=$?
    while [[ $r == 0 ]]; do
        sleep 1
        now=$(date +%s)
        if [[ $(( now - start )) -gt 120 ]]; then
            echo "SLOW SETUP : $(( now - start )) SECONDS .. LOOK AT THIS"
        fi
        kill -0 $pid >/dev/null 2>&1
        r=$?
    done
    return 0
}

#
# Find cores from running a test -- primarily aimed to find cores from the
# comdb2 executable in the directory where cores are saved.
# If core_pattern is the default 'core' then it will find and report any cores 
# in the TESTDIR, even those from other programs.
# If core_pattern includes name (%e) and pid (%p), then we will search 
# in the cores directory (if not set then in TESTDIR) for core file 
# containing comdb2 and pid in core filename.
find_cores() {
    if [ $OSTYPE != "linux-gnu" ] ; then
        return
    fi
    # assumes core location and pattern is the same as local machine
    # for all machines in cluster 
    local LCLDBNM=$1
    local LCLDBDIR=$2
    local COREAGE=${FINDCOREAGE:-60}
    local CPAT=$(< /proc/sys/kernel/core_pattern)  # like cat core_pattern
    [[ "${CPAT:0:1}" == "|" ]] && CPAT=core  #TODO: handle cores controled by coredumpctl
    local COREDIR=$(dirname $CPAT 2>/dev/null)
    if [ "x$COREDIR" == "x" ] || [ "x$COREDIR" == "x." ] ; then  # when just 'core'
        COREDIR=$LCLDBDIR
    else
        CPAT=`basename $CPAT`
    fi
    local has_pattern=0  # We assume core pattern is same for all machines
    grep '%e\|%t\|%u\|%g\|%s\|%h\|%p' /proc/sys/kernel/core_pattern > /dev/null && has_pattern=1
    local COREFL="$COREDIR/$CPAT"
    local CORECMD="find ${COREDIR} -mmin -$COREAGE -regex '$COREFL' 2> /dev/null"
    local PIDFL=${TMPDIR}/${LCLDBNM}.pid

    eval cr=\$\(${CORECMD}\)       # or can do cr=$(eval ${CORECMD}) or cr=$(find ${COREDIR} | grep $COREFL)

    # always check localhost because thats where we create db
    if [[ -z "${cr}" ]] && [[ $has_pattern -eq 1 ]] ; then
        local PID=$(cat ${PIDFL} 2> /dev/null)
        COREFL=`echo $CPAT | sed "s/%e/comdb2/g; s/.%t/.[^.]*/g; s/.%u/.[^.]*/g; s/.%g/.[^.]*/; s/.%s/.[^.]*/; s/.%h/.[^.]*/; s/%p/$PID/g; s/\.\./\./;"`
        COREFL=$COREDIR/$COREFL
        CORECMD="find ${COREDIR} -mmin -$COREAGE -regex '${COREFL}.*' 2> /dev/null"
        if [ "x$PID" == "x" ] ; then
            CORECMD="echo ''"
        fi
    fi

    eval cr=\$\(${CORECMD}\)       # or can do cr=$(eval ${CORECMD}) or cr=$(find ${COREDIR} | grep $COREFL)
    if [[ -n "$cr" ]] ; then
        echo "Core file $HOSTNAME:${cr} copied to $LCLDBDIR" > $LCLDBDIR/core_stacktrace.$HOSTNAME.txt
        if [ ! -f $cr ] ; then 
            ln ${cr} -t $LCLDBDIR || cp ${cr} $LCLDBDIR #if can't hardlink then just copy
        fi
        which gdb > /dev/null && [ -f $cr ] && echo 'where' | gdb -q $COMDB2_EXE $cr &>> $LCLDBDIR/core_stacktrace.$HOSTNAME.txt
        which gdb > /dev/null && [ -f $cr ] && echo 't a a bt full' | gdb -q $COMDB2_EXE $cr &>> $LCLDBDIR/core_stacktrace_long.$HOSTNAME.txt
        ln $COMDB2_EXE -t $LCLDBDIR #make a hardlink of the executable as well
        echo $cr # this is the return value of the function
        echo "    see $LCLDBDIR/core_stacktrace.$HOSTNAME.txt"
    fi


    if [[ -n "$CLUSTER" ]] ; then
        #check again for clustered local crash
        PIDFL=${TMPDIR}/${LCLDBNM}.$HOSTNAME.pid
        if [ $has_pattern -eq 1 ] ; then
            local PID=$(cat ${PIDFL} 2> /dev/null)
            COREFL=`echo $CPAT | sed "s/%e/comdb2/g; s/.%t/.[^.]*/g; s/.%u/.[^.]*/g; s/.%g/.[^.]*/; s/.%s/.[^.]*/; s/.%h/.[^.]*/; s/%p/$PID/g; s/\.\./\./;"`
            COREFL=$COREDIR/$COREFL
            CORECMD="find ${COREDIR} -mmin -$COREAGE -regex '${COREFL}.*' 2> /dev/null"
            if [ "x$PID" == "x" ] ; then
                CORECMD="echo ''"
            fi
        fi

        eval cr=\$\(${CORECMD}\)       # or can do cr=$(eval ${CORECMD}) or cr=$(find ${COREDIR} | grep $COREFL)
        if [[ -n "$cr" ]] ; then
            echo "Core file $HOSTNAME:${cr} copied to $LCLDBDIR" > $LCLDBDIR/core_stacktrace.$HOSTNAME.txt
            cp ${cr} $LCLDBDIR
            which gdb > /dev/null && [ -f $cr ] && echo 'where' | gdb -q $COMDB2_EXE $cr &>> $LCLDBDIR/core_stacktrace.$HOSTNAME.txt
            which gdb > /dev/null && [ -f $cr ] && echo 't a a bt full' | gdb -q $COMDB2_EXE $cr &>> $LCLDBDIR/core_stacktrace_long.$HOSTNAME.txt
            ln $COMDB2_EXE -t $LCLDBDIR #make a hardlink of the executable as well
            echo $cr # this is the return value of the function
            echo "    see $LCLDBDIR/core_stacktrace.$HOSTNAME.txt"
        fi
    fi

    for node in ${CLUSTER} ; do
        if [ $node == $HOSTNAME ] ; then
            continue
        fi
        if [ $has_pattern -eq 1 ] ; then
            PIDFL=${TMPDIR}/${LCLDBNM}.pid
            local PID=`ssh -n -o StrictHostKeyChecking=no $node "cat ${PIDFL} 2> /dev/null"`
            if [ "x$PID" == "x" ] ; then
                continue
            fi
            COREFL=`echo $CPAT | sed "s/%e/comdb2/g; s/.%t/.[^.]*/g; s/.%u/.[^.]*/g; s/.%g/.[^.]*/; s/.%s/.[^.]*/; s/.%h/.[^.]*/; s/%p/$PID/g; s/\.\./\./;"`
            COREFL=$COREDIR/$COREFL
            CORECMD="find ${COREDIR} -mmin -$COREAGE -regex '${COREFL}.*' 2> /dev/null"
        fi

        cr=`ssh -n -o StrictHostKeyChecking=no $node "$CORECMD"`

        if [[ -n "$cr" ]] ; then
            echo "$node:$cr" # this is the return value of the function
            local space=$(df .  | awk '{print $4}' | grep -v Available)
            local size=$(ssh -n -o StrictHostKeyChecking=no $node "ls -s $cr | cut -f1 -d' '")
            if [[ $size -lt $space ]] ; then # if there is space, copy locally
                local copy_core=$LCLDBDIR/${node}.`basename $cr`
                scp -o StrictHostKeyChecking=no $node:${cr} $copy_core
                echo "Core file $node:${cr} copied to $copy_core" > $LCLDBDIR/core_stacktrace.$node.txt
                echo 'where' | gdb -q $COMDB2_EXE $copy_core &>> $LCLDBDIR/core_stacktrace.$node.txt
                echo 't a a bt full' | gdb -q $COMDB2_EXE $copy_core &>> $LCLDBDIR/core_stacktrace_long.$node.txt
                ln $COMDB2_EXE -t $LCLDBDIR #make a hardlink of the executable as well
                echo "    see $LCLDBDIR/core_stacktrace.$node.txt"
            else
                echo "No space to copy core located at $node:${cr}"
            fi
        fi
    done
}

verify_physical_at_finish() {
    local LCLDBNM="$1"
    local LCLCONFIG="$2"
    local LCLOPTIONS="--cdb2cfg ${LCLCONFIG}"

    if [[ -z "$CLUSTER" ]]; then
        timeout 1m $CDB2SQL_EXE ${LCLOPTIONS} --tabs $LCLDBNM default "exec procedure sys.cmd.send('flush')" >/dev/null 2>&1
        ls ${DBDIR}/ | egrep "\.datas|\.index|\.blobs" | while read fl ; do 
            ${CDB2VERIFY_EXE} ${DBDIR}/$fl 
            if [[ $? != 0 ]]; then
                echo "${DBDIR}/$fl failed physical verify"
                return
            fi
        done
    else
        for node in ${CLUSTER} ; do
            timeout 1m $CDB2SQL_EXE ${LCLOPTIONS} --tabs $LCLDBNM --host $node "exec procedure sys.cmd.send('flush')" >/dev/null 2>&1
            ck=`ssh -o StrictHostKeyChecking=no $node "ls ${DBDIR}/ | egrep \"\.datas|\.index|\.blobs\" | while read fl ; do ${CDB2VERIFY_EXE} ${DBDIR}/\\\${fl} ; if [[ \\\$? != 0 ]]; then echo \"$node:${DBDIR}/\\\${fl} failed verify\" ; break 2 ; fi ; done" < /dev/null`
            if [[ -n "$ck" ]]; then
                echo "$ck"
                return
            fi
        done
    fi
}

call_setup() {
    [[ $COMDB2_UNITTEST == 1 ]] && return

    if [[ $SETUP_WARN ]]; then
         warn_long_setup
         rc=$?
    else
        { timeout --kill-after=5s ${SETUP_TIMEOUT} ${TESTSROOTDIR}/setup 2>&1 || echo $?; } | gawk '{ print strftime("%H:%M:%S>"), $0; fflush(); }' | tee ${TESTDIR}/logs/${DBNAME}.setup | cut -c11- | grep "^!"
    fi
    sleep 0.8 # wait a bit for any cores
    #last line of .setup file will contain the error rc if any
    ret=`tail -1 ${TESTDIR}/logs/${DBNAME}.setup | cut -c11-`

    cr=`find_cores ${DBNAME} $DBDIR`

    if [[ -z "${cr}" ]] && [[ -n "${SECONDARY_DBNAME}" ]] ; then
        cr=`find_cores ${SECONDARY_DBNAME} ${SECONDARY_DBDIR}`
    fi

    if [[ -z "${cr}" ]] && [[ -n "${TERTIARY_DBNAME}" ]] ; then
        cr=`find_cores ${TERTIARY_DBNAME} ${TERTIARY_DBDIR}`
    fi

    if [[ -z "${cr}" ]] && [[ -n "${QUATERNARY_DBNAME}" ]] ; then
        cr=`find_cores ${QUATERNARY_DBNAME} ${QUATERNARY_DBDIR}`
    fi

    if [[ -z "${cr}" ]] && [[ -n "${QUINARY_DBNAME}" ]] ; then
        cr=`find_cores ${QUINARY_DBNAME} ${QUINARY_DBDIR}`
    fi

    if [[ -z "${cr}" ]] && [[ -n "${SENARY_DBNAME}" ]] ; then
        cr=`find_cores ${SENARY_DBNAME} ${SENARY_DBDIR}`
    fi

    if [[ -n "${cr}" ]] ; then
        echo "!$TESTCASE: setup failed with core dumped ($cr)" | tee -a ${TEST_LOG}
        call_unsetup
        sleep 0.1
        exit 1
    elif [[ $ret != "setup successful" ]] ; then
        echo "!$TESTCASE: setup failed (rc=$ret)" >> ${TEST_LOG}
        echo "!$TESTCASE: setup failed (rc=$ret) see ${TESTDIR}/logs/${DBNAME}.setup"
        call_unsetup
        sleep 0.1
        exit 1
    fi
}


# check if we can perform a 'select 1' query to the db
check_db_at_finish() {
    local LCLDBNM="$1"
    local LCLCONFIG="$2"
    local LCLOPTIONS="--cdb2cfg ${LCLCONFIG}"

    if [[ -z "${CLUSTER}" ]] ; then
        out=$(timeout --kill-after=5s 1m $CDB2SQL_EXE ${LCLOPTIONS} --tabs --host localhost $LCLDBNM 'select 1' 2>&1)
        if [ "$out" != "1" ] ; then
            timeout --kill-after=5s 1m $CDB2SQL_EXE -v ${LCLOPTIONS} --tabs --host localhost $LCLDBNM 'select 1' &> ${TESTDIR}/logs/${LCLDBNM}.atfinish
            echo $out
            return
        fi

    fi
    for node in ${CLUSTER} ; do
        out=$(timeout --kill-after=5s 1m $CDB2SQL_EXE ${LCLOPTIONS} --tabs --host $node $LCLDBNM 'select 1' 2>&1)
        if [ "$out" != "1" ] ; then
            timeout --kill-after=5s 1m $CDB2SQL_EXE -v ${LCLOPTIONS} --tabs --host $node $LCLDBNM 'select 1' &> ${TESTDIR}/logs/${LCLDBNM}.${node}.atfinish
            echo $out
            return
        fi
    done
}

# run verify on all the tables of the db
verify_db_at_finish() {
    local LCLDBNM="$1"
    local LCLCONFIG="$2"
    local LCLOPTIONS="--cdb2cfg ${LCLCONFIG}"

    node=$(timeout --kill-after=5s 1m $CDB2SQL_EXE ${LCLOPTIONS} --tabs $LCLDBNM default 'select comdb2_host()' )
    tables=$(timeout --kill-after=5s 1m $CDB2SQL_EXE ${LCLOPTIONS} --tabs $LCLDBNM --host $node 'select * from comdb2_tables where tablename not in (select name from comdb2_timepartitions)')
    for t in $tables ; do 
        outfl=${t}_verify.out
        timeout --kill-after=5s 3m $CDB2SQL_EXE ${LCLOPTIONS} --verbose --tabs $LCLDBNM --host $node "exec procedure sys.cmd.verify('$t', 'parallel')" &> $outfl
        if ! grep "^Verify succeeded.$" $outfl > /dev/null ; then
            echo "Table $t"
            return
        fi
    done
}

exit_if_above_max_test_failures () {
    MAX_TEST_FAILURES=10    # stop running if more that this number of failures in test.log
    F=`grep failed ${TESTDIR}/test.log | wc -l`
    if [ "$F" -ge "$MAX_TEST_FAILURES" ] ; then 
        echo "$TESTCASE: Max number of allowed test failures ($MAX_TEST_FAILURES) reached" >> ${TESTDIR}/test.log
        exit 1; 
    fi
}

exit_if_above_max_test_failures


# start the testing: setup, runit, check cores, unsetup

call_setup

DATETIME=$(date +"%Y-%m-%d %H:%M:%S")
echo "!$TESTCASE: started running with timeout ${TEST_TIMEOUT} at $DATETIME"

if [[ "x${DEBUGGER}" == "xcallgrind" ]]; then
    callgrind_control -i on
fi

timeout --kill-after=5s ${TEST_TIMEOUT} ./runit ${DBNAME} 2>&1  | gawk '{ print strftime("%H:%M:%S>"), $0; fflush(); }' &> ${TESTDIR}/logs/${DBNAME}.testcase
rc=${PIPESTATUS[0]}

DATETIME=$(date +"%Y-%m-%d %H:%M:%S")
echo "!$TESTCASE: finished running with timeout ${TEST_TIMEOUT} at $DATETIME"

# get the return code from the first phase of the pipe
sleep 1

if [[ "x${DEBUGGER}" == "xcallgrind" ]]; then
    callgrind_control -i off
fi

cr=`find_cores ${DBNAME} $DBDIR`

#-z true if the length is zero
if [[ -z "${cr}" ]] && [[ -n "${SECONDARY_DBNAME}" ]] ; then
    cr=`find_cores ${SECONDARY_DBNAME} ${SECONDARY_DBDIR}`
fi

if [[ -z "${cr}" ]] && [[ -n "${TERTIARY_DBNAME}" ]] ; then
    cr=`find_cores ${TERTIARY_DBNAME} ${TERTIARY_DBDIR}`
fi

if [[ -z "${cr}" ]] && [[ -n "${QUATERNARY_DBNAME}" ]] ; then
    cr=`find_cores ${QUATERNARY_DBNAME} ${QUATERNARY_DBDIR}`
fi

if [[ -z "${cr}" ]] && [[ -n "${QUINARY_DBNAME}" ]] ; then
    cr=`find_cores ${QUINARY_DBNAME} ${QUINARY_DBDIR}`
fi

if [[ -z "${cr}" ]] && [[ -n "${SENARY_DBNAME}" ]] ; then
    cr=`find_cores ${SENARY_DBNAME} ${SENARY_DBDIR}`
fi

if [[ -n "$cr" ]] ; then
    CHECK_DB_AT_FINISH=0
elif [[ -z "${CHECK_DB_AT_FINISH}" ]] ; then
   if [[ "$COMDB2_UNITTEST" != 1 ]] ; then
       CHECK_DB_AT_FINISH=1
   else
       CHECK_DB_AT_FINISH=0
   fi
fi
    


if [ $CHECK_DB_AT_FINISH -eq 1 ] ; then
    dbdown=`check_db_at_finish ${DBNAME} $CDB2_CONFIG`

    # if no crashes, check secondary/tertiary
    if [[ -z "${dbdown}" ]] && [[ -n "${SECONDARY_DBNAME}" ]]; then
        dbdown=`check_db_at_finish ${SECONDARY_DBNAME} $SECONDARY_CDB2_CONFIG`
    fi

    if [[ -z "${dbdown}" ]] && [[ -n "${TERTIARY_DBNAME}" ]]; then
        dbdown=`check_db_at_finish ${TERTIARY_DBNAME} $TERTIARY_CDB2_CONFIG`
    fi

    if [[ -z "${dbdown}" ]] && [[ -n "${QUATERNARY_DBNAME}" ]]; then
        dbdown=`check_db_at_finish ${QUATERNARY_DBNAME} $QUATERNARY_CDB2_CONFIG`
    fi

    if [[ -z "${dbdown}" ]] && [[ -n "${QUINARY_DBNAME}" ]]; then
        dbdown=`check_db_at_finish ${QUINARY_DBNAME} $QUINARY_CDB2_CONFIG`
    fi

    if [[ -z "${dbdown}" ]] && [[ -n "${SENARY_DBNAME}" ]]; then
        dbdown=`check_db_at_finish ${SENARY_DBNAME} $SENARY_CDB2_CONFIG`
    fi

    # if no crashes and $VERIFY_DB_AT_FINISH > 0 then run verify
    if [[ -z "${dbdown}" ]] && [[ $VERIFY_DB_AT_FINISH -gt 0 ]]; then
        verify_ret=`verify_db_at_finish ${DBNAME} $CDB2_CONFIG`
        # if no issues with verify, run verify on secondary/tertiary
        if [[ -z "${verify_ret}" ]] && [[ -n "${SECONDARY_DBNAME}" ]]; then
            verify_ret=`verify_db_at_finish ${SECONDARY_DBNAME} $SECONDARY_CDB2_CONFIG`
        fi
        if [[ -z "${verify_ret}" ]] && [[ -n "${TERTIARY_DBNAME}" ]]; then
            verify_ret=`verify_db_at_finish ${TERTIARY_DBNAME} $TERTIARY_CDB2_CONFIG`
        fi
        if [[ -z "${verify_ret}" ]] && [[ -n "${QUATERNARY_DBNAME}" ]]; then
            verify_ret=`verify_db_at_finish ${QUATERNARY_DBNAME} $QUATERNARY_CDB2_CONFIG`
        fi
        if [[ -z "${verify_ret}" ]] && [[ -n "${QUINARY_DBNAME}" ]]; then
            verify_ret=`verify_db_at_finish ${QUINARY_DBNAME} $QUINARY_CDB2_CONFIG`
        fi
        if [[ -z "${verify_ret}" ]] && [[ -n "${SENARY_DBNAME}" ]]; then
            verify_ret=`verify_db_at_finish ${SENARY_DBNAME} $SENARY_CDB2_CONFIG`
        fi

        verify_phys=`verify_physical_at_finish ${DBNAME} $CDB2_CONFIG`
    fi
fi

RED=""
GREEN=""
YELLOW=""
NEUTRAL=""
#if we are outputing to a terminal, show failure in red text
if [ -t 1 ] ; then
    RED="\033[0;31m"
    GREEN="\033[0;32m"
    YELLOW="\033[0;33m"
    NEUTRAL="\033[0m"
fi

if [[ -n "$dbdown" ]] ; then
    # if this is intentional, please run test with 'CHECK_DB_AT_FINISH=0' (ex. put in test Makefile:export CHECK_DB_AT_FINISH=0)
    echo "!$TESTCASE: db was unavailable at finish ($dbdown)" | tee -a ${TEST_LOG}
elif [[ $rc -eq 124 ]] ; then
    echo -e "!$TESTCASE: ${YELLOW}timeout${NEUTRAL} (logs in ${TESTDIR}/logs/${DBNAME}.testcase)"
    echo "!$TESTCASE: timeout" >> ${TEST_LOG}
    successful=-1
elif [[ -n "$verify_ret" ]] && [[ $rc -ne 0 ]] ; then
    echo -e "!$TESTCASE: ${RED}failed${NEUTRAL} rc=$rc (logs in ${TESTDIR}/logs/${DBNAME}.testcase)"
    echo "!$TESTCASE: failed" >> ${TEST_LOG}
    echo -e "!$TESTCASE: also ${RED}failed${NEUTRAL} verify ($verify_ret)"
    echo "!$TESTCASE: also failed verify ($verify_ret)" >> ${TEST_LOG}
elif [[ -n "$verify_phys" ]] && [[ $rc -ne 0 ]]; then
    echo "!$TESTCASE: failed rc=$rc (logs in ${TESTDIR}/logs/${DBNAME}.testcase)"
    echo "!$TESTCASE: failed" >> ${TEST_LOG}
    echo "!$TESTCASE: also failed physical-verify ($verify_phys)" | tee -a ${TEST_LOG}
elif [[ -n "$verify_phys" ]]; then
    echo "!$TESTCASE: failed physical-verify ($verify_phys)" | tee -a ${TEST_LOG}
elif [[ -f "${DBNAME}.failexit" ]] ; then
    echo -e "!$TESTCASE: ${RED}failed${NEUTRAL} (found ${DBNAME}.failexit, logs in ${TESTDIR}/logs/${DBNAME}.testcase)"
    echo "!$TESTCASE: failed (found ${DBNAME}.failexit)" >> ${TEST_LOG}
elif [[ -n "$verify_ret" ]] ; then
    echo -e "!$TESTCASE: ${RED}failed${NEUTRAL} verify ($verify_ret)"
    echo "!$TESTCASE: failed verify ($verify_ret)" >> ${TEST_LOG}
elif [[ -n "$cr" ]] ; then
    # if this is intentional, please move core before test exits
    echo -e "!$TESTCASE: ${RED}failed${NEUTRAL} with core dumped ($cr)"
    echo "!$TESTCASE: failed with core dumped ($cr)" >> ${TEST_LOG}
    cr=""
elif [[ $rc -eq 0 ]] ; then
    echo -e "!$TESTCASE: ${GREEN}success${NEUTRAL} (logs in ${TESTDIR}/logs/${DBNAME}.testcase)"
    echo "!$TESTCASE: success" >> ${TEST_LOG}
    successful=1
else
    echo -e "!$TESTCASE: ${RED}failed${NEUTRAL} rc=$rc (logs in ${TESTDIR}/logs/${DBNAME}.testcase)"
    echo "!$TESTCASE: failed" >> ${TEST_LOG}
fi

if [[ -n "$cr" ]] ; then
    echo -e "!$TESTCASE: also ${RED}core${NEUTRAL} dumped ($cr)"
    echo "!$TESTCASE: also core dumped ($cr)" >> ${TEST_LOG}
fi

trap - INT EXIT

call_unsetup

if [[ -z "$cr" ]] ; then
    # find any cores after unsetup -- ONLY works if CLEANUPDBDIR=0 because unsetup cleans up dir
    cr=`find_cores ${DBNAME} $DBDIR`

    if [[ -z "${cr}" ]] && [[ -n "${SECONDARY_DBNAME}" ]] ; then
        cr=`find_cores ${SECONDARY_DBNAME} ${SECONDARY_DBDIR}`
    fi

    if [[ -z "${cr}" ]] && [[ -n "${TERTIARY_DBNAME}" ]] ; then
        cr=`find_cores ${TERTIARY_DBNAME} ${TERTIARY_DBDIR}`
    fi

    if [[ -z "${cr}" ]] && [[ -n "${QUATERNARY_DBNAME}" ]] ; then
        cr=`find_cores ${QUATERNARY_DBNAME} ${QUATERNARY_DBDIR}`
    fi

    if [[ -z "${cr}" ]] && [[ -n "${QUINARY_DBNAME}" ]] ; then
        cr=`find_cores ${QUINARY_DBNAME} ${QUINARY_DBDIR}`
    fi

    if [[ -z "${cr}" ]] && [[ -n "${SENARY_DBNAME}" ]] ; then
        cr=`find_cores ${SENARY_DBNAME} ${SENARY_DBDIR}`
    fi

    if [[ -n "$cr" ]] ; then
        echo "!$TESTCASE: at unsetup found core ($cr)" | tee -a ${TEST_LOG}
        exit 1
    fi
fi

DATETIME=$(date +"%Y-%m-%d %H:%M:%S")
echo Done $TESTCASE with id $TESTID at $DATETIME >> ${TEST_LOG}
echo "Duration $SECONDS seconds" >> ${TESTDIR}/logs/${DBNAME}.testcase

if [[ "${DEBUG_PREFIX}" == "valgrind"* ]]; then 
   echo "${DEBUGGER} files are located here:"
   ls ${TESTDIR}/*.*grind
elif [[ "${DEBUGGER}" == *"perf" ]]; then 
   echo "perf files are located here:"
   ls ${TESTDIR}/*.perfdata
fi

exit $rc
