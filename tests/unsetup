#!/usr/bin/env bash

set -x

[[ $COMDB2_UNITTEST == 1 ]] && exit 0

echo "!$TESTCASE: stopping"
[ -z "$TESTDIR" ] && TESTDIR=${PWD}/test_${TESTID}
[ -z "$TMPDIR" ] && TMPDIR=${TESTDIR}/tmp

#parameter $1 indicates if test is successful or not
successful=$1

function kill_by_pidfile() {
    pidfile=$1
    if [[ -f $pidfile ]]; then
        local pid=$(cat $pidfile)
        local pstr=$(ps -p $pid -o args | grep comdb2)
        echo $pstr | grep -q "comdb2 ${DBNAME}"
        if [[ $? -eq 0 ]]; then
            echo "${TESTCASE}: killing $pid"
            if [ "`echo $pstr | awk '{ print $1 }' | xargs basename`" = "comdb2" ] ; then
                kill -9 $pid
            else
                kill $pid
            fi
        fi
        rm -f $pidfile
    else
        echo "kill_by_pidfile: pidfile $pidfile does not exist"
    fi
}

function build_pidfilelist() {
    pidfile=$1
    if [[ -f $pidfile ]]; then
        local pid=$(cat $pidfile)
        ps -p $pid -o args | grep -q "comdb2 ${DBNAME}"
        if [[ $? -eq 0 ]]; then 
            echo "${TESTCASE}: adding to filelist $pid"
            pidfilelist="$pidfilelist $pid"
            rm -f $pidfile
        fi
    else
        echo "kill_by_pidfile: pidfile $pidfile does not exist"
    fi
}

core_all_nodes() {
    local node
    local PIDFL=${TMPDIR}/${DBNAME}.pid
    if [[ -z "$CLUSTER" ]] || [[ `echo $CLUSTER | grep $HOSTNAME ` ]]; then
        if [[ -n "$CLUSTER" ]] ; then
            PIDFL=${TMPDIR}/${DBNAME}.$HOSTNAME.pid
        fi
        cat ${PIDFL} | xargs kill -6 
    fi

    for node in ${CLUSTER/$HOSTNAME/} ; do
         PIDFL=${TMPDIR}/${DBNAME}.pid
         ssh -o StrictHostKeyChecking=no $node "cat ${PIDFL} | xargs kill -6 " </dev/null
    done
}


function cleanup_cluster {    
    for node in $CLUSTER; do
        if [ "$node" != "$HOSTNAME" ] ; then
            ${TESTSROOTDIR}/tools/send_msg_port.sh -h $node "get comdb2/replication/${DBNAME}" ${pmux_port}
            ssh -o StrictHostKeyChecking=no $node "${deregister_db_port}" < /dev/null
        fi
        if [ "x$DBDIR" == "x" ] ; then 
            continue
        fi
        if [ "$node" == "$HOSTNAME" ]  ; then
            continue;
        fi

        if [ "$successful" != "1" ] ; then 
            echo copy $node:${TESTDIR} content locally to $TESTDIR/$node for investigation
            scp -r -o StrictHostKeyChecking=no $node:${DBDIR} $DBDIR/$node < /dev/null
        elif [ "$CLEANUPDBDIR" == "1" ] ; then 
            ssh -o StrictHostKeyChecking=no $node "rm -rf ${DBDIR}" < /dev/null
        fi
    done
}

echo deregistering $DBNAME from pmux:$pmux_port
deregister_db_port="pgrep pmux > /dev/null && (exec 3<>/dev/tcp/localhost/${pmux_port}; echo del comdb2/replication/${DBNAME} >&3 )"

if [[ "$NOKILL_ON_TIMEOUT" -eq 1 && "$successful" -eq "-1" ]]; then
    echo "Unsetup deferred"
    exit 0
fi

if [[ "$CORE_ON_TIMEOUT" -eq "1" && "$successful" -eq "-1" ]]; then
    core_all_nodes
fi


if [[ -z "$CLUSTER" ]]; then
    cdb2sql ${CDB2_OPTIONS} $DBNAME default 'exec procedure sys.cmd.send("flush")' &
    sleep 1
    cdb2sql ${CDB2_OPTIONS} $DBNAME default 'exec procedure sys.cmd.send("reql events off")' &
    sleep 1
    
    kill_by_pidfile ${TMPDIR}/${DBNAME}.pid

else
    pidfilelist=""

    for node in $CLUSTER; do
        cdb2sql ${CDB2_OPTIONS} $DBNAME --host $node 'exec procedure sys.cmd.send("flush")' &
        sleep 1
        cdb2sql ${CDB2_OPTIONS} $DBNAME --host $node 'exec procedure sys.cmd.send("reql events off")' &
        sleep 1
        build_pidfilelist ${TMPDIR}/${DBNAME}.${node}.pid
    done

    # for clustered, killing ssh session which is running comdb2 cmd 
    # will kill server on that node
    if [ -n "$pidfilelist" ] ; then
        echo "killing $pidfilelist"
        kill -9 $pidfilelist
    fi
    cleanup_cluster
fi

eval $deregister_db_port

if [ "$CLEANUPDBDIR" == "1" ] && [ "$successful" == "1" ] && [ "x$DBDIR" != "x" ] ; then 
    rm -rf ${DBDIR}
    rm -rf ${TESTDIR}/var/log/cdb2/${DBNAME}.*
fi

echo "Unsetup completed"
