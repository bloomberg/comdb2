#!/usr/bin/env bash
bash -n "${0}" || exit 1

source "${TESTSROOTDIR}/tools/cluster_utils.sh"
source "${TESTSROOTDIR}/tools/runit_common.sh"

set -e
DBNAME="${1}"

#declare -rx debug=1

function create_table()
{
    "${CDB2SQL_EXE}" ${CDB2_OPTIONS} "${DBNAME}" default "create table t (i int)"
}

function populate_table()
{
    # Adjust the number of rows inserted based on whether we are running against
    # cluster vs. standalone. The latter is able to rebuild the table faster and
    # thus may not run long enough to exercise the logic of this test.
    local -r num_iter=$(if [[ -n "${CLUSTER}" ]]; then echo 300; else echo 1000; fi)

    for i in `seq 1 ${num_iter}`; do
        "${CDB2SQL_EXE}" ${CDB2_OPTIONS} "${DBNAME}" default "insert into t select * from generate_series(1, 1000)"
    done
}

function spam_queries()
{
    # Spam queries to generate statreqs while schema change is running.
    while true; do
        "${CDB2SQL_EXE}" ${CDB2_OPTIONS} "${DBNAME}" default "delete from t limit 1" > /dev/null
    done
}

function run_schema_change()
{
    # Trigger a schema change that will cover multiple iterations of the statthd loop.
    "${CDB2SQL_EXE}" ${CDB2_OPTIONS} "${DBNAME}" default "rebuild t"
}

function filter_logs()
{
    local -r logfile="${1}"
    local -r start_time="${2}"
    local -r end_time="${3}"

    awk -f "${TESTDIR}/${TESTCASE}.test/filter.awk" -v start="${start_time}" -v end="${end_time}" "${logfile}"
}

function extract_log_timestamps()
{
    local -r logfile="${1}"

    awk -f "${TESTDIR}/${TESTCASE}.test/extract_timestamps.awk" "${logfile}" | sort -nu
}

function extract_sc_stats_timestamps()
{
    local -r logfile="${1}"

    awk -f "${TESTDIR}/${TESTCASE}.test/extract_sc_stats_timestamps.awk" "${logfile}" | sort -nu
}

function verify_log_continuity()
{
    local -r timestamps_file="${1}"
    local -r start_time="${2}"
    local -r end_time="${3}"
    local -r node="${4}"  # only for logging purposes

    local missing_timestamps=()

    for (( timestamp = start_time; timestamp <= end_time; timestamp++ )); do
        if ! grep -q "^${timestamp}$" "${timestamps_file}"; then
            missing_timestamps+=("${timestamp}")
        fi
    done

    # If we are missing statreqs for more than 30% of the time (chosen
    # arbitrarily) during which schema change was running, something might
    # be broken.
    local -r num_missing=${#missing_timestamps[@]}
    local -r total=$( wc -l < "${timestamps_file}" )

    if (( num_missing > total * 3 / 10 )); then
        echo "Available timestamps on node '${node}' in ${timestamps_file}:"
        echo
        cat "${timestamps_file}"
        echo
        echo "Missing statreqs for the following timestamps on node '${node}':"
        echo
        for timestamp in "${missing_timestamps[@]}"; do
            echo "${timestamp}"
        done
        echo
        failexit "Missing statreqs for more than 30% of the time during schema change on '${node}'"
    fi
}

function verify_logs_for_node()
{
    local -r logfile="${1}"
    local -r start_time="${2}"
    local -r end_time="${3}"
    local -r node="${4}"
    local -r is_master="${5}"

    # Filter logs to only include entries between when schema change started and ended.
    filter_logs "${logfile}" "${start_time}" "${end_time}" > "${logfile}.filtered"

    if [[ -n "${debug}" ]]; then
        echo
        echo "Full log contents on node ${node}:"
        echo
        cat "${logfile}"
        echo
        echo "Filtered log contents on node ${node} (between ${start_time} and ${end_time}):"
        echo
        cat "${logfile}.filtered"
        echo
    fi
    
    # Check that for every second between when schema change started and ended,
    # we got _something_ in statreqs. Ignore 3 seconds before and after to give
    # some leeway.
    extract_log_timestamps "${logfile}.filtered" > "${logfile}.filtered.timestamps"
    verify_log_continuity "${logfile}.filtered.timestamps" $(( start_time + 3 )) $(( end_time - 3 )) "${node}"

    if [[ "${is_master}" == "1" ]]; then
        # Check that for every second between when schema change started and ended,
        # we got 'SCHEMA CHANGE STATS' in statreqs. Ignore 3 seconds before and after to give
        # some leeway.
        echo "${node} is master, checking that schema change stats are present in statreqs"
        extract_sc_stats_timestamps "${logfile}.filtered" > "${logfile}.filtered.sc_timestamps"
        verify_log_continuity "${logfile}.filtered.sc_timestamps" $(( start_time + 3 )) $(( end_time - 3 )) "${node}"
    fi
}

function verify_logs()
{
    local -r start_time="${1}"
    local -r end_time="${2}"
    local -r master="${3}"

    src="${TESTDIR}/var/log/cdb2/${DBNAME}.statreqs"

    if [[ -n "${CLUSTER}" ]]; then
        for node in ${CLUSTER}; do
            # Grab logs from node.
            local dest="${TESTDIR}/logs/${DBNAME}_${node}.statreqs"
            ssh -o StrictHostKeyChecking=no "${node}" "cat ${src}" > "${dest}"

            local is_master=$(if [[ "${node}" == "${master}" ]]; then echo 1; else echo 0; fi)
            verify_logs_for_node "${dest}" "${start_time}" "${end_time}" "${node}" "${is_master}"
        done
    else
        # Single node case.
        local dest="${TESTDIR}/logs/${DBNAME}_standalone.statreqs"
        cp "${src}" "${dest}"

        local -r is_master=1  # treat as master because we should have 'SCHEMA CHANGE STATS' in statreqs
        verify_logs_for_node "${dest}" "${start_time}" "${end_time}" "standalone" "${is_master}"
    fi
}

function main()
{
    # Set up dummy data.
    create_table
    populate_table

    # Run schema change and spam queries at the same time.
    spam_queries &
    spam_pid=$!

    local -r master=$(get_master)
    echo "Master is ${master}"
    local -r rebuild_start_time=$(date +%s)
    echo "Starting schema change at $(date -d @${rebuild_start_time} '+%m/%d %H:%M:%S')"
    run_schema_change
    local -r rebuild_end_time=$(date +%s)
    echo "Finished schema change at $(date -d @${rebuild_end_time} '+%m/%d %H:%M:%S')"

    # Stop spamming queries.
    kill "${spam_pid}"

    # Give time for log files to flush.
    sleep 1

    # Check that we got statreqs on all nodes from the spam queries despite
    # schema change running at the same time.
    verify_logs "${rebuild_start_time}" "${rebuild_end_time}" "${master}"
}

main
echo "Success"
